# ==============================================================================
# FILE: api.py
# CH·ª®C NƒÇNG: Backend Server (FastAPI) + LLM Reranker + Feedback Loop
# ==============================================================================
import re
import json
import csv
import os
import uvicorn
import random
import json
import pandas as pd
from datetime import datetime
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Dict
from fastapi import BackgroundTasks
from difflib import SequenceMatcher
from config import GEMINI_API_KEY
# Import Core Engine & Gemini Client
try:
    from recommender_engine import CarRecommendationSystem
    from google import genai
    from google.genai import types
except ImportError as e:
    print(f"‚ùå L·ªói Import: {e}")
    exit()

# ==============================================================================
# 1. C·∫§U H√åNH & KH·ªûI T·∫†O
# ==============================================================================


app = FastAPI(title="Smart Car RecSys API")

# C·∫•u h√¨nh CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Kh·ªüi t·∫°o H·ªá th·ªëng G·ª£i √Ω & AI Client
print("‚è≥ ƒêang kh·ªüi ƒë·ªông h·ªá th·ªëng...")
try:
    # Load Engine v·ªõi file CSV m·ªõi
    recsys = CarRecommendationSystem(csv_path="scraped_cars.csv") 
    gemini_client = genai.Client(api_key=GEMINI_API_KEY)
    print("‚úÖ H·ªá th·ªëng ƒë√£ s·∫µn s√†ng!")
except Exception as e:
    print(f"‚ùå L·ªói kh·ªüi t·∫°o: {e}")
    recsys = None
# C·∫•u h√¨nh file log feedback
FEEDBACK_FILE = "user_interactions_log.csv"

# Kh·ªüi t·∫°o file CSV n·∫øu ch∆∞a t·ªìn t·∫°i
if not os.path.exists(FEEDBACK_FILE):
    with open(FEEDBACK_FILE, mode='w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        # Header chu·∫©n ƒë·ªÉ sau n√†y train l·∫°i model
        writer.writerow(["timestamp", "user_id", "car_id", "action", "implied_rating"])

# Database gi·∫£ l·∫≠p l∆∞u l·ªãch s·ª≠ t∆∞∆°ng t√°c (User-User CF foundation)
user_interactions = {} 
# ==============================================================================
# 2. DATA MODELS (Pydantic)
# ==============================================================================
def log_feedback_to_csv(user_id: str, car_id: str, action: str):
    """
    H√†m ch·∫°y ng·∫ßm: Ghi log t∆∞∆°ng t√°c v√†o CSV ƒë·ªÉ sau n√†y retrain model.
    Quy ƒë·ªïi:
    - like    -> Rating 5.0
    - dislike -> Rating 1.0
    - view    -> Rating 3.0 (V√≠ d·ª• xem chi ti·∫øt xe)
    """
    # 1. Quy ƒë·ªïi h√†nh ƒë·ªông sang ƒëi·ªÉm s·ªë (Implicit Feedback)
    rating_map = {
        "like": 5.0,
        "dislike": 1.0,
        "view": 3.0,
        "contact": 5.0 # N·∫øu user b·∫•m n√∫t li√™n h·ªá
    }
    
    implied_rating = rating_map.get(action, 0)
    
    # 2. Ghi v√†o file
    try:
        with open(FEEDBACK_FILE, mode='a', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow([
                datetime.now().isoformat(),
                user_id,
                car_id,
                action,
                implied_rating
            ])
        print(f"üíæ [System] ƒê√£ l∆∞u feedback: {user_id} -> {action} -> {car_id}")
    except Exception as e:
        print(f"‚ùå L·ªói ghi file feedback: {e}")

    # 3. C·∫≠p nh·∫≠t b·ªô nh·ªõ Session (ƒë·ªÉ d√πng cho t√≠nh nƒÉng 'User-User' t·ª©c th√¨)
    # N·∫øu user like, ta l∆∞u l·∫°i ƒë·ªÉ g·ª£i √Ω xe t∆∞∆°ng t·ª± ngay trong phi√™n ƒë√≥
    if action == "like":
        if user_id not in user_interactions:
            user_interactions[user_id] = []
        if car_id not in user_interactions[user_id]:
            user_interactions[user_id].append(car_id)

class UserProfileReq(BaseModel):
    age: int = 25
    income: int = 10000000
    maritalStatus: str = "single"      # 'single' | 'married'
    purpose: str = "commute"           # 'commute' | 'travel' | 'service' | 'family'
    priceRange: Optional[List[int]] = None  # [min, max]
    preferredBrands: Optional[List[str]] = []
    transmission: Optional[str] = "any"     # 'any' | 'manual' | 'automatic'

class ChatRequest(BaseModel):
    message: str
    userProfile: UserProfileReq
    history: Optional[List[Dict[str, str]]] = []
    sessionId: Optional[str] = "guest"

class FeedbackRequest(BaseModel):
    user_id: str 
    car_id: str
    action: str # "like" | "dislike"
# ==============================================================================
# 3. HELPER FUNCTIONS: MAPPING & LLM LOGIC
# ==============================================================================

def map_car_to_frontend(row, match_score=0):
    """
    Chuy·ªÉn ƒë·ªïi 1 d√≤ng d·ªØ li·ªáu t·ª´ CSV (ph·∫≥ng) sang JSON (l·ªìng nhau) cho FE.
    X·ª≠ l√Ω c√°c tr∆∞·ªùng thi·∫øu ho·∫∑c ƒë·ªãnh d·∫°ng l·∫°i.
    """
    # X·ª≠ l√Ω c√°c gi√° tr·ªã an to√†n
    def safe_str(val): return str(val) if pd.notna(val) else ""
    def safe_int(val, default=0): 
        try: return int(float(val)) if pd.notna(val) else default
        except: return default

    # 1. Th√¥ng tin c∆° b·∫£n
    car_id = safe_str(row.get('id'))
    name = safe_str(row.get('name'))
    brand = safe_str(row.get('brand'))
    
    # 2. X·ª≠ l√Ω Features (Trong CSV l√† chu·ªói "A, B, C" -> List ["A", "B", "C"])
    raw_features = safe_str(row.get('features'))
    features_list = [f.strip() for f in raw_features.split(',')] if raw_features else []
    
    # Gi·ªõi h·∫°n hi·ªÉn th·ªã t·ªëi ƒëa 5 feature n·ªïi b·∫≠t ƒë·ªÉ UI kh√¥ng b·ªã v·ª°
    if len(features_list) > 5:
        features_list = features_list[:5]

    return {
        "id": car_id,
        "name": name,
        "brand": brand,
        "year": safe_int(row.get('year'), 2020),
        "price": safe_int(row.get('price'), 0),
        "image": safe_str(row.get('image')), 
        "seats": safe_int(row.get('seats'), 5),
        "transmission": safe_str(row.get('transmission')),
        "fuelType": safe_str(row.get('fuelType')),
        
        "matchScore": int(match_score),
        "matchReason": "Ph√π h·ª£p v·ªõi nhu c·∫ßu v√† s·ªü th√≠ch c·ªßa b·∫°n.",
        
        # 3. Gom nh√≥m Specs (Nested Object)
        "specs": {
            "engine": safe_str(row.get('engine', 'N/A')),
            "horsepower": safe_int(row.get('horsepower') if 'horsepower' in row else row.get('power'), 100),
            "torque": safe_str(row.get('torque', 'N/A')),
            "fuelConsumption": safe_str(row.get('fuelConsumption', 'N/A')),
            "dimensions": safe_str(row.get('dimensions', 'N/A')),
            "weight": safe_str(row.get('weight', 'N/A'))
        },
        
        "description": safe_str(row.get('description', 'ƒêang c·∫≠p nh·∫≠t th√¥ng tin...')),
        "features": features_list
    }


# ==============================================================================
# 5. LLM RERANKER (GEMINI)
# ==============================================================================


def llm_rerank_and_explain(user_msg, user_profile, car_list):
    """
    üíé AI CONSULTANT (L·ªúI GI·∫¢I TH√çCH TH√îNG MINH)
    Ch·ª©c nƒÉng:
    1. Nh·∫≠n v√†o Top 3 xe t·ªët nh·∫•t t·ª´ Engine (ƒë√£ ƒë∆∞·ª£c s·∫Øp x·∫øp theo ƒëi·ªÉm).
    2. Ph√¢n t√≠ch t√¢m l√Ω ng∆∞·ªùi d√πng (Psychological Profiling).
    3. Vi·∫øt l·ªùi t∆∞ v·∫•n b√°n h√†ng thuy·∫øt ph·ª•c (Persuasive Copywriting) cho 3 xe n√†y.
    """
    
    # 1. CHU·∫®N B·ªä D·ªÆ LI·ªÜU (Ch·ªâ m√¥ t·∫£ 3 xe ƒë∆∞·ª£c truy·ªÅn v√†o)
    cars_context = ""
    for i, car in enumerate(car_list):
        # L·∫•y t·ªëi ƒëa 5 t√≠nh nƒÉng
        feats = ", ".join(car.get('features', [])[:5]) if car.get('features') else "C∆° b·∫£n"
        specs = car.get('specs', {})
        
        cars_context += (
            f"--- ·ª®NG VI√äN S·ªê {i+1}: {car['name']} ---\n"
            f"- Th√¥ng s·ªë: {car['year']}, {car['brand']}, {car['seats']} ch·ªó, {car['transmission']}\n"
            f"- Gi√°: {car['price']:,} VNƒê\n"
            f"- ƒêi·ªÉm ph√π h·ª£p h·ªá th·ªëng ch·∫•m: {car.get('matchScore', 0)}/100\n"
            f"- L√Ω do k·ªπ thu·∫≠t: {car.get('matchReason', '')}\n"
            f"- T√≠nh nƒÉng: {feats}\n\n"
        )

    # 2. X√ÇY D·ª∞NG PROMPT (Gi·ªØ nguy√™n ph·∫ßn Persona x·ªãn x√≤)
    tone_instruction = "Chuy√™n nghi·ªáp, tin c·∫≠y v√† kh√°ch quan."
    if user_profile.income > 25000000 or user_profile.age > 45:
        tone_instruction = "Sang tr·ªçng, l·ªãch thi·ªáp, t√¥n tr·ªçng ƒë·∫≥ng c·∫•p kh√°ch h√†ng (g·ªçi l√† 'qu√Ω kh√°ch')."
    elif user_profile.age < 30:
        tone_instruction = "Tr·∫ª trung, nƒÉng ƒë·ªông, t·∫≠p trung v√†o c√¥ng ngh·ªá, t·ªëc ƒë·ªô v√† s·ª± s√†nh ƒëi·ªáu."
    elif user_profile.purpose == "family":
        tone_instruction = "·∫§m √°p, quan t√¢m, nh·∫•n m·∫°nh s·ª± an to√†n, r·ªông r√£i v√† ti·ªán nghi cho gia ƒë√¨nh."

    prompt = f"""
    [VAI TR√í]
    B·∫°n l√† m·ªôt chuy√™n gia t∆∞ v·∫•n xe h∆°i cao c·∫•p (AI Concierge) v·ªõi 20 nƒÉm kinh nghi·ªám.
    
    [NHI·ªÜM V·ª§]
    H·ªá th·ªëng t√≠nh to√°n k·ªπ thu·∫≠t ƒë√£ l·ªçc ra 3 chi·∫øc xe ph√π h·ª£p nh·∫•t b√™n d∆∞·ªõi.
    Nhi·ªám v·ª• c·ªßa b·∫°n KH√îNG PH·∫¢I L√Ä CH·ªåN L·∫†I, m√† l√† vi·∫øt m·ªôt ƒëo·∫°n l·ªùi tho·∫°i t∆∞ v·∫•n th·∫≠t hay ƒë·ªÉ gi·ªõi thi·ªáu 3 chi·∫øc xe n√†y t·ªõi kh√°ch h√†ng.

    [H·ªí S∆† KH√ÅCH H√ÄNG]
    - Tu·ªïi: {user_profile.age} | Thu nh·∫≠p: {user_profile.income} USD/nƒÉm
    - T√¨nh tr·∫°ng h√¥n nh√¢n: {user_profile.maritalStatus} | M·ª•c ƒë√≠ch: {user_profile.purpose}
    - C√¢u h·ªèi/Nhu c·∫ßu: "{user_msg}"

    [DANH S√ÅCH 3 XE T·ªêT NH·∫§T]
    {cars_context}

    [Y√äU C·∫¶U N·ªòI DUNG]
    1. M·ªü ƒë·∫ßu: Ch√†o h·ªèi theo gi·ªçng ƒëi·ªáu {tone_instruction}.
    2. Ph√¢n t√≠ch nhanh: Nh·∫Øc kh√©o t·∫°i sao c√°c xe n√†y l·∫°i h·ª£p v·ªõi nhu c·∫ßu (v√≠ d·ª•: "V√¨ anh c·∫ßn xe gia ƒë√¨nh an to√†n n√™n t√¥i ch·ªçn...").
    3. ƒêi·ªÉm nh·∫•n: N√™u b·∫≠t 1 ∆∞u ƒëi·ªÉm "ƒë·∫Øt gi√°" nh·∫•t c·ªßa xe ƒë·ª©ng ƒë·∫ßu (·ª®ng vi√™n s·ªë 1).
    4. K·∫øt th√∫c: M·ªùi kh√°ch xem chi ti·∫øt b√™n d∆∞·ªõi.
    5. ƒê·ªô d√†i: Ng·∫Øn g·ªçn, s√∫c t√≠ch (d∆∞·ªõi 80 t·ª´).

    [Y√äU C·∫¶U ƒê·∫¶U RA]
    Tr·∫£ v·ªÅ ƒë·ªãnh d·∫°ng JSON chu·∫©n (RFC 8259), KH√îNG Markdown:
    {{
        "analysis": "L·ªùi t∆∞ v·∫•n c·ªßa b·∫°n ·ªü ƒë√¢y..."
    }}
    """

    # 3. G·ªåI API GEMINI
    try:
        response = gemini_client.models.generate_content(
            model="gemini-2.5-flash", # Ho·∫∑c gemma-3-4b-it t√πy b·∫°n
            contents=prompt,
            config=types.GenerateContentConfig(
                temperature=0.7, # TƒÉng nhi·ªát ƒë·ªô ch√∫t ƒë·ªÉ vƒÉn phong t·ª± nhi√™n h∆°n
                top_p=0.9,
            )
        )
        
        raw_text = response.text.strip()
        
        # 4. PARSING JSON
        json_match = re.search(r'\{.*\}', raw_text, re.DOTALL)
        if json_match:
            result = json.loads(json_match.group(0))
            return result
        else:
            # Fallback n·∫øu AI kh√¥ng tr·∫£ JSON
            return {"analysis": raw_text}

    except Exception as e:
        print(f"‚ö†Ô∏è [AI Explain Error] {e}")
        return {"analysis": "D∆∞·ªõi ƒë√¢y l√† nh·ªØng l·ª±a ch·ªçn t·ªët nh·∫•t ƒë∆∞·ª£c h·ªá th·ªëng t·ªïng h·ª£p d·ª±a tr√™n nhu c·∫ßu c·ªßa b·∫°n."}
    
def analyze_user_intent(message: str):
    """
    üß† ADVANCED INTENT RECOGNITION SYSTEM (NLU Engine)
    Ch·ª©c nƒÉng:
    1. Ph√¢n lo·∫°i √Ω ƒë·ªãnh ch√≠nh x√°c (Search, Compare, Consult, Chitchat).
    2. Tr√≠ch xu·∫•t Entities c·ª±c m·∫°nh: Gi√° ti·ªÅn (VNƒê), D√°ng xe, H·ªôp s·ªë, M·ª•c ƒë√≠ch s·ª≠ d·ª•ng.
    3. Chu·∫©n h√≥a d·ªØ li·ªáu ƒë·∫ßu v√†o cho b·ªô l·ªçc.
    """
    
    # Prompt k·ªπ thu·∫≠t "Few-Shot Learning" ƒë·ªÉ d·∫°y AI c√°ch x·ª≠ l√Ω c√°c case kh√≥
    prompt = f"""
    B·∫°n l√† m·ªôt NLU Engine (B·ªô hi·ªÉu ng√¥n ng·ªØ t·ª± nhi√™n) chuy√™n bi·ªát cho ng√†nh √¥ t√¥ t·∫°i Vi·ªát Nam.
    Nhi·ªám v·ª•: Ph√¢n t√≠ch c√¢u chat c·ªßa kh√°ch h√†ng v√† tr√≠ch xu·∫•t d·ªØ li·ªáu c√≥ c·∫•u tr√∫c (JSON).

    C√¢u chat: "{message}"
    [QUY T·∫ÆC ∆ØU TI√äN QUAN TR·ªåNG]
    - N·∫øu ng∆∞·ªùi d√πng ƒë∆∞a ra y√™u c·∫ßu c·ª• th·ªÉ trong c√¢u chat (v√≠ d·ª•: "t√¨m xe Honda"), ƒë√¢y l√† **HARD CONSTRAINT**.
    - C√°c th√¥ng tin c≈© (nh∆∞ user th√≠ch Toyota trong qu√° kh·ª©) ph·∫£i b·ªã ghi ƒë√® b·ªüi y√™u c·∫ßu hi·ªán t·∫°i.
    [QUY T·∫ÆC TR√çCH XU·∫§T]
    1. **Intent (√ù ƒë·ªãnh):**
       - "search": T√¨m mua xe, h·ªèi gi√°, h·ªèi th√¥ng tin xe c·ª• th·ªÉ.
       - "compare": So s√°nh 2 ho·∫∑c nhi·ªÅu xe c·ª• th·ªÉ (VD: "Vios hay Accent h∆°n?").
       - "compare_generic": Mu·ªën so s√°nh nh∆∞ng ch∆∞a n√≥i xe n√†o (VD: "So s√°nh gi√∫p m√¨nh").
       - "consult_service": H·ªèi v·ªÅ d·ªãch v·ª•, b·∫£o d∆∞·ª°ng, th·ªß t·ª•c gi·∫•y t·ªù.
       - "chitchat": Ch√†o h·ªèi, khen ch√™, n√≥i chuy·ªán phi·∫øm kh√¥ng li√™n quan xe.

    2. **Smart Filters (B·ªô l·ªçc th√¥ng minh):**
       - **Price (Gi√°):** N·∫øu user n√≥i "t·∫ßm 500tr", "d∆∞·ªõi 1 t·ª∑", "1 t·ªèi 2"... h√£y quy ƒë·ªïi ra s·ªë nguy√™n VNƒê.
         -> price_min: int ho·∫∑c 0
         -> price_max: int ho·∫∑c 0 (N·∫øu "t·∫ßm 500tr" -> min 450tr, max 550tr).
       - **Body Type (D√°ng xe):** Map t·ª´ kh√≥a:
         "g·∫ßm cao" -> ["suv", "mpv", "crossover"]
         "xe gia ƒë√¨nh" -> ["mpv", "suv", "sedan"]
         "xe ch·ªü h√†ng", "b√°n t·∫£i" -> ["pickup"]
         "xe nh·ªè", "ƒëi ph·ªë" -> ["hatchback", "sedan"]
       - **Transmission:** "t·ª± ƒë·ªông"/"AT" -> "automatic", "s·ªë s√†n"/"MT" -> "manual".
       - **Fuel:** "m√°y d·∫ßu" -> "diesel", "m√°y xƒÉng" -> "petrol", "xe ƒëi·ªán" -> "electric".
       - **Usage (M·ª•c ƒë√≠ch - Context):** "ch·∫°y d·ªãch v·ª•", "grab" -> "service"; "ƒëi ph∆∞·ª£t" -> "travel"; "cho v·ª£ ƒëi ch·ª£" -> "daily".
       - **Features (T√≠nh nƒÉng):** Tr√≠ch xu·∫•t list c√°c t·ª´ kh√≥a: ["sunroof" (c·ª≠a s·ªï tr·ªùi), "360_camera" (cam 360), "leather" (gh·∫ø da), "adas" (an to√†n/sensing), "smartkey"].
       - **Performance (Hi·ªáu su·∫•t):** N·∫øu user d√πng t·ª´ "m·∫°nh m·∫Ω", "b·ªëc", "th·ªÉ thao", "ƒë·∫°p s∆∞·ªõng" -> set "high_performance": true.
       - **Condition (T√¨nh tr·∫°ng):** "xe l∆∞·ªõt", "m·ªõi c·ª©ng" -> "like_new"; "xe c≈©", "gi√° r·∫ª" -> "used".
       - **Strictness (ƒê·ªô kh·∫Øt khe):** 
         - N·∫øu user d√πng t·ª´: "ch·ªâ mua", "b·∫Øt bu·ªôc", "ph·∫£i l√†" -> set "strict_mode": true.
         - N·∫øu user n√≥i: "g·ª£i √Ω", "tham kh·∫£o", "t·∫ßm t·∫ßm" -> set "strict_mode": false.
    3. **Brands:** Tr√≠ch xu·∫•t t√™n h√£ng (Toyota, Mazda, Mercedes...) -> lowercase.

    [Y√äU C·∫¶U ƒê·∫¶U RA]
    Tr·∫£ v·ªÅ JSON duy nh·∫•t, format chu·∫©n RFC 8259. KH√îNG th√™m markdown (```json).
    Format m·∫´u:
    {{
        "is_car_related": true,
        "intent": "search",
        "mentioned_brands": ["toyota"],
        "filters": {{
            "price_min": 0,
            "price_max": 600000000,
            "min_year": 2018,
            "body_type": ["sedan", "hatchback"],
            "transmission": "automatic",
            "fuel_type": null,
            "min_seats": 0,
            "features": ["sunroof", "adas"],  
            "high_performance": true,         
            "car_condition": "like_new",
            "strict_mode": false       
        }},
        "user_context": {{
            "usage": "family", 
            "priority": "safety" (n·∫øu kh√°ch nh·∫Øc ƒë·∫øn an to√†n, b·ªÅn b·ªâ...)
        }},
        "reply_suggestion": "C√¢u tr·∫£ l·ªùi x√£ giao n·∫øu is_car_related=false"
    }}
    """
    
    try:
        # C·∫•u h√¨nh model ƒë·ªÉ tr·∫£ v·ªÅ k·∫øt qu·∫£ nh·∫•t qu√°n (Deterministic)
        response = gemini_client.models.generate_content(
            model="gemini-2.5-flash", # N√™n d√πng Flash cho t·ªëc ƒë·ªô v√† Logic t·ªët
            contents=prompt,
            config=types.GenerateContentConfig(
                temperature=0.0, # Nhi·ªát ƒë·ªô = 0 ƒë·ªÉ tr√≠ch xu·∫•t ch√≠nh x√°c tuy·ªát ƒë·ªëi
                top_p=1.0,
            )
        )
        
        raw_text = response.text.strip()
        
        # üõ°Ô∏è ROBUST PARSING (Ch·ªëng l·ªói JSON)
        # S·ª≠ d·ª•ng Regex ƒë·ªÉ t√¨m block JSON h·ª£p l·ªá
        json_match = re.search(r'\{.*\}', raw_text, re.DOTALL)
        if json_match:
            data = json.loads(json_match.group(0))
            
            # Post-processing (X·ª≠ l√Ω h·∫≠u k·ª≥ an to√†n)
            filters = data.get("filters", {})
            
            # ƒê·∫£m b·∫£o c√°c field quan tr·ªçng lu√¥n t·ªìn t·∫°i ƒë·ªÉ Code ph√≠a sau kh√¥ng l·ªói
            final_data = {
                "is_car_related": data.get("is_car_related", True),
                "intent": data.get("intent", "search"),
                "mentioned_brands": data.get("mentioned_brands", []),
                "filters": {
                    "min_year": filters.get("min_year"),
                    "min_power": filters.get("min_power"),
                    "fuel_type": filters.get("fuel_type"),
                    "min_seats": filters.get("min_seats"),
                    # C√°c field n√¢ng c·∫•p m·ªõi
                    "price_min": filters.get("price_min", 0),
                    "price_max": filters.get("price_max", 0),
                    "features": filters.get("features", []),
                    "high_performance": filters.get("high_performance", False),
                    "car_condition": filters.get("car_condition", "any"),
                    "body_type": filters.get("body_type", []), # List
                    "transmission": filters.get("transmission", "any")
                },
                "user_context": data.get("user_context", {}),
                "reply_suggestion": data.get("reply_suggestion", "")
            }
            
            print(f"üß† [NLU Analysis] Intent: {final_data['intent']} | Brands: {final_data['mentioned_brands']}")
            if final_data['filters']['price_max']:
                 print(f"   -> Detected Budget: {final_data['filters']['price_min']:,} - {final_data['filters']['price_max']:,} VNƒê")
                 
            return final_data

        else:
            raise ValueError("No JSON found")

    except Exception as e:
        print(f"‚ö†Ô∏è [NLU Error] Ph√¢n t√≠ch th·∫•t b·∫°i: {e}")
        # Fallback an to√†n t·ªëi ƒëa
        return {
            "is_car_related": True, 
            "intent": "search", 
            "mentioned_brands": [], 
            "filters": {}, 
            "user_context": {},
            "reply_suggestion": ""
        }
    
# ==============================================================================
# 2. LOGIC L·ªåC TH√îNG MINH & CAO C·∫§P (ADVANCED SMART FILTER)
# ==============================================================================

def is_text_similar(a: str, b: str, threshold=0.7):
    """Ki·ªÉm tra 2 chu·ªói c√≥ gi·ªëng nhau kh√¥ng (ch·∫•p nh·∫≠n l·ªói ch√≠nh t·∫£ nh·∫π)"""
    return SequenceMatcher(None, a.lower(), b.lower()).ratio() > threshold

def apply_smart_filters(candidates_df, user_profile: UserProfileReq, intent_data: dict):
    """
    üß† CONTEXT-AWARE SOFT FILTERING
    Nguy√™n t·∫Øc: 
    1. Chat Context > User Profile (L·ªùi n√≥i hi·ªán t·∫°i quan tr·ªçng nh·∫•t).
    2. Soft Penalty: Kh√¥ng x√≥a xe, ch·ªâ tr·ª´ ƒëi·ªÉm n·∫øu kh√¥ng kh·ªõp.
    3. Fallback: N·∫øu tr·ª´ ƒëi·ªÉm qu√° tay khi·∫øn list r·ªóng, tr·∫£ v·ªÅ xe ƒëi·ªÉm cao nh·∫•t d√π th·∫•p.
    """
    scored_candidates = []
    
    # 1. L·∫•y d·ªØ li·ªáu Context (∆Øu ti√™n cao nh·∫•t)
    chat_brands = [b.lower() for b in intent_data.get("mentioned_brands", [])]
    extracted_filters = intent_data.get("filters", {}) or {}
    
    # Check ch·∫ø ƒë·ªô kh·∫Øt khe (do AI ph√°n ƒëo√°n)
    is_strict = extracted_filters.get("strict_mode", False)
    
    for _, row in candidates_df.iterrows():
        # L·∫•y ƒëi·ªÉm g·ªëc t·ª´ Engine (ƒë√£ t√≠nh to√°n vector t∆∞∆°ng ƒë·ªìng)
        # Gi·∫£ s·ª≠ ƒëi·ªÉm g·ªëc dao ƒë·ªông 60-90
        base_score = float(row.get('match_percent', 70))
        current_score = base_score
        
        car_obj = map_car_to_frontend(row, match_score=base_score)
        car_brand = car_obj['brand'].lower()
        car_price = car_obj['price']
        
        reasons = [] # Ghi l·∫°i l√Ω do b·ªã tr·ª´ ƒëi·ªÉm ƒë·ªÉ debug ho·∫∑c gi·∫£i th√≠ch

        # ---------------------------------------------------------
        # A. LOGIC H√ÉNG XE (BRAND) - Priority: Chat > Profile
        # ---------------------------------------------------------
        if chat_brands:
            # User ƒêANG h·ªèi v·ªÅ h√£ng n√†y -> Ki·ªÉm tra k·ªπ
            match_found = False
            for brand in chat_brands:
                if brand in car_brand or is_text_similar(brand, car_brand):
                    match_found = True
                    break
            
            if match_found:
                current_score += 15 # C·ªông ƒëi·ªÉm m·∫°nh v√¨ ƒë√∫ng √Ω user ngay l√∫c n√†y
            else:
                # Sai h√£ng user ƒëang h·ªèi
                penalty = 60 if is_strict else 30 # N·∫øu user "ch·ªâ mua Audi" -> tr·ª´ 60, c√≤n "tham kh·∫£o" -> tr·ª´ 30
                current_score -= penalty
                reasons.append(f"Kh√¥ng ph·∫£i h√£ng {chat_brands[0]}")
                
        elif user_profile.preferredBrands:
            # User KH√îNG n√≥i h√£ng n√†o trong chat -> D√πng Profile (∆Øu ti√™n th·∫•p h∆°n)
            if any(pb.lower() in car_brand for pb in user_profile.preferredBrands):
                current_score += 5 # C·ªông nh·∫π
            # Kh√¥ng tr·ª´ ƒëi·ªÉm n·∫øu kh√¥ng kh·ªõp profile (ƒë·ªÉ user kh√°m ph√° h√£ng m·ªõi)

        # ---------------------------------------------------------
        # B. LOGIC GI√Å TI·ªÄN (PRICE) - Fuzzy Range
        # ---------------------------------------------------------
        # ∆Øu ti√™n gi√° trong chat (context) -> r·ªìi m·ªõi t·ªõi profile
        target_min = extracted_filters.get("price_min") or user_profile.priceRange[0]
        target_max = extracted_filters.get("price_max") or user_profile.priceRange[1]
        
        # N·∫øu target_max = 0 ho·∫∑c qu√° l·ªõn (v√¥ l√Ω), b·ªè qua check max
        if target_max > 100000000: # > 100tr m·ªõi check
            if car_price > target_max:
                # T√≠nh ƒë·ªô l·ªách gi√° (Over-budget)
                diff_percent = (car_price - target_max) / target_max
                
                if diff_percent < 0.1: # L·ªë < 10% (VD: C√≥ 1 t·ª∑, xe 1 t·ª∑ 1) -> OK
                    current_score -= 5 
                elif diff_percent < 0.3: # L·ªë < 30% -> Tr·ª´ v·ª´a
                    current_score -= 20
                    reasons.append("V∆∞·ª£t ng√¢n s√°ch")
                else: # L·ªë qu√° nhi·ªÅu -> Tr·ª´ n·∫∑ng
                    current_score -= 50
                    reasons.append("Gi√° qu√° cao")
            
            elif car_price < target_min * 0.8: # R·∫ª h∆°n qu√° nhi·ªÅu (VD: t√¨m xe sang m√† g·ª£i √Ω xe c·ªè)
                current_score -= 10 
                reasons.append("Gi√° th·∫•p h∆°n mong ƒë·ª£i")

        # ---------------------------------------------------------
        # C. LOGIC NƒÇM & C√îNG NGH·ªÜ (Technical Specs)
        # ---------------------------------------------------------
        req_min_year = extracted_filters.get("min_year")
        if req_min_year and car_obj['year'] < req_min_year:
            # M·ªói nƒÉm c≈© h∆°n tr·ª´ 3 ƒëi·ªÉm
            diff = req_min_year - car_obj['year']
            current_score -= (diff * 3)
            if diff > 5: reasons.append("ƒê·ªùi xe h∆°i s√¢u")

        # ---------------------------------------------------------
        # D. T·ªîNG K·∫æT & CH·ªêT
        # ---------------------------------------------------------
        # Clip ƒëi·ªÉm (0-100)
        final_score = max(0, min(100, int(current_score)))
        
        car_obj['matchScore'] = final_score
        # N·∫øu c√≥ l√Ω do tr·ª´ ƒëi·ªÉm, update v√†o matchReason (ƒë·ªÉ hi·ªÉn th·ªã UI n·∫øu mu·ªën)
        if reasons:
            car_obj['matchReason'] = f"L∆∞u √Ω: {', '.join(reasons)}"
        
        # Ng∆∞·ª°ng s√†n: Ch·ªâ l·∫•y xe tr√™n 40 ƒëi·ªÉm
        if final_score >= 40:
            scored_candidates.append(car_obj)

    # S·∫Øp x·∫øp gi·∫£m d·∫ßn theo ƒëi·ªÉm
    scored_candidates.sort(key=lambda x: x['matchScore'], reverse=True)
    
    # --- FALLBACK TH√îNG MINH ---
    # N·∫øu l·ªçc xong m√† r·ªóng (do tr·ª´ ƒëi·ªÉm qu√° tay), tr·∫£ v·ªÅ top 3 xe c√≥ ƒëi·ªÉm cao nh·∫•t trong ƒë√°m b·ªã lo·∫°i
    # ƒê·ªÉ tr√°nh vi·ªác tr·∫£ v·ªÅ r·ªóng ho√†n to√†n
    if not scored_candidates and candidates_df is not None and len(candidates_df) > 0:
        print("‚ö†Ô∏è Soft filter qu√° g·∫Øt, k√≠ch ho·∫°t Rescue Mode.")
        # L·∫•y l·∫°i t·∫•t c·∫£, sort v√† tr·∫£ v·ªÅ top 3
        backup_list = []
        for _, row in candidates_df.iterrows():
            backup_list.append(map_car_to_frontend(row, match_score=40))
        return backup_list[:3]

    return scored_candidates

# ==============================================================================
# 4. API ENDPOINTS
# ==============================================================================

@app.post("/api/chat")
async def chat_endpoint(req: ChatRequest):
    """
    Lu·ªìng x·ª≠ l√Ω ch√≠nh:
    1. Map Input FE -> Backend Context
    2. Recommender Engine -> L·∫•y 50 xe ti·ªÅm nƒÉng (Retrieval)
    3. API Filters -> L·ªçc theo Gi√°, H√£ng, H·ªôp s·ªë (Post-Filtering)
    4. LLM Rerank -> Ch·ªçn 3 xe t·ªët nh·∫•t & Vi·∫øt l·ªùi tho·∫°i (Reranking)
    5. Return -> JSON chu·∫©n cho FE
    """
    print(f"üì© Chat Request: {req.message}")
    print(f"   Profile: {req.userProfile}")
    # 1. B∆Ø·ªöC 1: PH√ÇN T√çCH √ù ƒê·ªäNH (INTENT ANALYSIS)
    intent_data = analyze_user_intent(req.message)
    print(f"üß† Intent: {intent_data}")

    # 2. X·ª¨ L√ù CASE 1: KH√îNG LI√äN QUAN / T√ÄO LAO / CHITCHAT
    if not intent_data.get("is_car_related", True) or intent_data.get("intent") == "chitchat":
        return {
            "role": "assistant",
            "content": intent_data.get("reply_suggestion", "T√¥i l√† tr·ª£ l√Ω ·∫£o chuy√™n v·ªÅ xe h∆°i. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n t√¨m chi·∫øc xe ∆∞ng √Ω kh√¥ng?"),
            "cars": [] # Kh√¥ng tr·∫£ v·ªÅ xe n√†o c·∫£ -> UI s·∫Ω kh√¥ng hi·ªán th·∫ª xe lung tung
        }

    # 3. X·ª¨ L√ù CASE 2: SO S√ÅNH CHUNG CHUNG (COMPARE GENERIC)
    # User: "So s√°nh ƒëi", "So s√°nh gi√∫p m√¨nh" (M√† kh√¥ng n√≥i xe n√†o)
    if intent_data.get("intent") == "compare_generic":
        return {
            "role": "assistant",
            "content": "B·∫°n mu·ªën so s√°nh nh·ªØng m·∫´u xe n√†o? H√£y ch·ªçn 'Th√™m v√†o so s√°nh' tr√™n c√°c th·∫ª xe, ho·∫∑c n√≥i r√µ t√™n 2 d√≤ng xe b·∫°n ƒëang ph√¢n v√¢n nh√© (V√≠ d·ª•: So s√°nh Vios v√† Accent).",
            "cars": [] # Kh√¥ng tr·∫£ v·ªÅ xe
        }
    
    age = req.userProfile.age
    income = req.userProfile.income # USD/nƒÉm
    purpose = req.userProfile.purpose
    marital = req.userProfile.maritalStatus

    # M·∫∑c ƒë·ªãnh
    persona = "Family"

    # Logic ∆∞u ti√™n:
    if income >= 50000000: # L∆∞∆°ng cao -> Auto l√† Boss
        persona = "Boss"
    elif purpose == "commute" and age < 25 and income < 3000000: # Tr·∫ª, l∆∞∆°ng th·∫•p, ƒëi l√†m -> Student
        persona = "Student"
    elif purpose == "service": # Ch·∫°y d·ªãch v·ª• -> C·∫ßn b·ªÅn -> Coi nh∆∞ Family/Commute
        persona = "Family"
    elif purpose == "travel": # ƒêi ph∆∞·ª£t -> Racer/Family
        persona = "Racer" if age < 30 else "Family"
    
    # ---------------------------------------------------------
    # 2. T·∫†O PROFILE ƒê·∫¶Y ƒê·ª¶ (C√°ch 2 n√¢ng c·∫•p)
    # ---------------------------------------------------------
    backend_profile = {
        "persona": persona,
        "age": age,
        "salary": income,
        "is_married": 1 if marital == 'married' else 0,
        "is_rich": True if income >= 50000000 else False,
        "liked_history": user_interactions.get(req.sessionId, [])
    }
    # 4.2. Merge th√™m c√°c b·ªô l·ªçc s√¢u t·ª´ LLM (NƒÉm, M√°y, Odo...)
    # 1. Truy·ªÅn H√£ng xe (VD: Audi)
    if intent_data.get("mentioned_brands"):
        backend_profile["specific_brands"] = intent_data["mentioned_brands"]
        print(f"üéØ [Engine] ∆Øu ti√™n l·ªçc h√£ng: {intent_data['mentioned_brands']}")

    # 2. Truy·ªÅn B·ªô l·ªçc chi ti·∫øt t·ª´ NLU (NƒÉm, Gi√°,...)
    extracted_filters = intent_data.get("filters", {})
    if extracted_filters:
        # Ch·ªâ l·∫•y c√°c gi√° tr·ªã kh√¥ng null
        clean_filters = {k: v for k, v in extracted_filters.items() if v is not None}
        if clean_filters.get('price_max'):
             backend_profile["max_price_override"] = clean_filters['price_max']
             
        backend_profile.update(clean_filters)

    # 2. G·ªçi Engine (L·∫•y d∆∞ ra 50 xe ƒë·ªÉ c√≤n l·ªçc l·∫°i)
    candidates_df = recsys.recommend(backend_profile, top_k=50)

    if candidates_df.empty:
        return {
            "role": "assistant",
            "content": "R·∫•t ti·∫øc, v·ªõi c√°c ti√™u ch√≠ k·ªπ thu·∫≠t kh·∫Øt khe nh∆∞ v·∫≠y, t√¥i ch∆∞a t√¨m th·∫•y chi·∫øc xe n√†o trong kho d·ªØ li·ªáu. B·∫°n th·ª≠ n·ªõi l·ªèng y√™u c·∫ßu (v√≠ d·ª• gi·∫£m ƒë·ªùi xe ho·∫∑c c√¥ng su·∫•t) xem sao nh√©?",
            "cars": []
        }

    # 4. √ÅP D·ª§NG SMART FILTER (POST-PROCESSING)
    # B∆∞·ªõc n√†y l·ªçc l·∫°i theo Gi√° ti·ªÅn, H√£ng (∆∞u ti√™n Chat > Profile)
    filtered_cars = apply_smart_filters(candidates_df, req.userProfile, intent_data)
    # filtered_cars = []
    
    # # Duy·ªát qua k·∫øt qu·∫£ t·ª´ Engine
    # for _, row in candidates_df.iterrows():
    #     # L·∫•y ƒëi·ªÉm s·ªë m√† Engine ƒë√£ t√≠nh (bao g·ªìm c·∫£ ƒëi·ªÉm c·ªông cho h√£ng/gi√° n·∫øu c√≥)
    #     score = row.get('match_percent', 85)
        
    #     # Chuy·ªÉn ƒë·ªïi sang format JSON cho Frontend
    #     car_obj = map_car_to_frontend(row, match_score=score)
        
    #     # N·∫øu mu·ªën, b·∫°n c√≥ th·ªÉ c·∫≠p nh·∫≠t matchReason c∆° b·∫£n ·ªü ƒë√¢y
    #     if intent_data.get("mentioned_brands"):
    #          # N·∫øu user h·ªèi h√£ng, v√† xe n√†y ƒë√∫ng h√£ng -> note l·∫°i
    #          requested_brands = [b.lower() for b in intent_data["mentioned_brands"]]
    #          if car_obj['brand'].lower() in requested_brands:
    #              car_obj['matchReason'] = "ƒê√∫ng th∆∞∆°ng hi·ªáu b·∫°n t√¨m"
        
    #     filtered_cars.append(car_obj)

    # print(f"üöÄ [Pipeline] Engine tr·∫£ v·ªÅ {len(filtered_cars)} xe -> Chuy·ªÉn th·∫≥ng cho LLM Rerank.")
    
    final_cars = []
    final_content = ""
    message_prefix = ""

    # 6. RERANKING & RESPONSE GENERATION (Chia nh√°nh Search vs Compare)
    
    # NH√ÅNH A: SO S√ÅNH (COMPARE)
    if intent_data.get("intent") == "compare" and len(filtered_cars) >= 2:
        # L·∫•y t·ªëi ƒëa 4 xe ƒë·ªÉ user so s√°nh
        final_cars = filtered_cars[:4]
        
        # Nh·ªù Gemini vi·∫øt ƒëo·∫°n so s√°nh ng·∫Øn
        car_names = ", ".join([c['name'] for c in final_cars])
        prompt = f"Kh√°ch h·ªèi: '{req.message}'. T√¥i t√¨m ƒë∆∞·ª£c: {car_names}. H√£y vi·∫øt ƒëo·∫°n ng·∫Øn (d∆∞·ªõi 50 t·ª´) m·ªùi kh√°ch b·∫•m v√†o n√∫t So s√°nh tr√™n c√°c th·∫ª xe."
        
        try:
            res = gemini_client.models.generate_content(model="gemini-2.5-flash", contents=prompt)
            final_content = message_prefix + res.text
        except:
            final_content = message_prefix + "D∆∞·ªõi ƒë√¢y l√† c√°c xe b·∫°n y√™u c·∫ßu. H√£y ch·ªçn 'Th√™m v√†o so s√°nh' ƒë·ªÉ xem chi ti·∫øt."

    # NH√ÅNH B: T√åM KI·∫æM (SEARCH) - M·∫∑c ƒë·ªãnh
    else:
        # --- B∆Ø·ªöC 1: SYSTEM SELECTION (H·ªá th·ªëng t·ª± ch·ªçn) ---
        # S·∫Øp x·∫øp danh s√°ch xe t·ª´ Engine theo ƒëi·ªÉm s·ªë matchScore (cao -> th·∫•p)
        # filtered_cars l√† danh s√°ch 50 xe t·ª´ Engine tr·∫£ v·ªÅ
        filtered_cars.sort(key=lambda x: x['matchScore'], reverse=True)
        
        # C·∫Øt l·∫•y Top 3 xe xu·∫•t s·∫Øc nh·∫•t
        final_cars = filtered_cars[:3]
        
        # N·∫øu kh√¥ng c√≥ xe n√†o (Fallback)
        if not final_cars:
            print("‚ö†Ô∏è Filter qu√° ch·∫∑t. D√πng Fallback.")
            fallback_df = recsys.df_cars.sample(3) 
            final_cars = [map_car_to_frontend(row, match_score=60) for _, row in fallback_df.iterrows()]
            message_prefix = "Hi·ªán ch∆∞a t√¨m th·∫•y xe ch√≠nh x√°c theo y√™u c·∫ßu, nh∆∞ng b·∫°n c√≥ th·ªÉ tham kh·∫£o: "

        # --- B∆Ø·ªöC 2: AI EXPLANATION ---
        # Ch·ªâ g·ªçi AI ƒë·ªÉ vi·∫øt l·ªùi tho·∫°i cho 3 xe ƒë√£ ch·ªët
        ai_response = llm_rerank_and_explain(req.message, req.userProfile, final_cars)
        
        # Gh√©p l·ªùi tho·∫°i
        final_content = message_prefix + ai_response.get("analysis", "ƒê√¢y l√† c√°c g·ª£i √Ω ph√π h·ª£p nh·∫•t.")

    # 7. TR·∫¢ K·∫æT QU·∫¢
    return {
        "role": "assistant",
        "content": final_content,
        "cars": final_cars
    }

@app.post("/api/feedback")
async def feedback_endpoint(req: FeedbackRequest, background_tasks: BackgroundTasks):
    """
    API nh·∫≠n Feedback t·ª´ Frontend.
    S·ª≠ d·ª•ng BackgroundTasks ƒë·ªÉ kh√¥ng block request c·ªßa user.
    """
    # 1. Validation c∆° b·∫£n (n·∫øu c·∫ßn)
    if not req.car_id or not req.user_id:
        return {"status": "error", "message": "Missing info"}

    print(f"üëç Feedback nh·∫≠n ƒë∆∞·ª£c: User {req.user_id} - {req.action} - Xe {req.car_id}")
    
    # 2. ƒê·∫©y vi·ªác ghi file v√†o n·ªÅn (Ch·∫°y song song, tr·∫£ response ngay l·∫≠p t·ª©c)
    background_tasks.add_task(log_feedback_to_csv, req.user_id, req.car_id, req.action)
    
    # 3. (Tu·ª≥ ch·ªçn n√¢ng cao) Real-time Update
    # N·∫øu h·ªá th·ªëng c·ª±c x·ªãn, t·∫°i ƒë√¢y c√≥ th·ªÉ g·ªçi h√†m update weight cho model
    # Nh∆∞ng v·ªõi ƒë·ªì √°n, vi·ªác l∆∞u log ƒë·ªÉ train sau l√† ƒë·ªß chu·∫©n.

    return {
        "status": "success", 
        "message": "Feedback recorded successfully",
        "timestamp": datetime.now().isoformat()
    }

@app.get("/api/similar/{car_id}")
def similar_cars_endpoint(car_id: str): # ƒê·ªïi th√†nh str ƒë·ªÉ nh·∫≠n m·ªçi lo·∫°i ID
    """
    Endpoint l·∫•y xe t∆∞∆°ng t·ª± (Hybrid Approach).
    K·∫øt h·ª£p s·ª©c m·∫°nh c·ªßa Matrix Factorization v√† Content Filtering.
    """
    try:
        # G·ªçi h√†m Hybrid m·ªõi
        similar_df = recsys.get_similar_cars_item_based(car_id, top_k=4)
        
        cars = []
        for _, row in similar_df.iterrows():
            # Xe t·ª´ CF th∆∞·ªùng c√≥ ƒë·ªô tin c·∫≠y cao h∆°n Content
            score = 90 if 'sim_score' not in row else int(row['sim_score']) # sim_score t·ª´ content-based logic
            
            # Clip score
            score = max(70, min(99, score))
            
            mapped_car = map_car_to_frontend(row, match_score=score)
            
            # C·∫≠p nh·∫≠t l√Ω do
            if 'sim_score' in row:
                mapped_car['matchReason'] = "T∆∞∆°ng ƒë·ªìng v·ªÅ th√¥ng s·ªë k·ªπ thu·∫≠t & t·∫ßm gi√°"
            else:
                mapped_car['matchReason'] = "ƒê∆∞·ª£c nhi·ªÅu ng∆∞·ªùi c√πng s·ªü th√≠ch quan t√¢m"
                
            cars.append(mapped_car)
            
        return cars
        
    except Exception as e:
        print(f"‚ùå Error getting similar cars: {e}")
        return []

@app.get("/api/cars")
def get_all_cars_endpoint():
    """
    API tr·∫£ v·ªÅ to√†n b·ªô danh s√°ch xe hi·ªán c√≥ trong kho d·ªØ li·ªáu (scraped_cars.csv).
    Ph·ª•c v·ª• cho trang Showroom ƒë·ªÉ hi·ªÉn th·ªã l∆∞·ªõi s·∫£n ph·∫©m.
    """
    if recsys is None or recsys.df_cars is None:
        return []

    try:
        all_cars = []
        # Duy·ªát qua to√†n b·ªô DataFrame xe
        # L∆∞u √Ω: N·∫øu d·ªØ li·ªáu > 10.000 xe, n√™n l√†m ph√¢n trang (pagination) ·ªü backend.
        # V·ªõi d·ªØ li·ªáu ƒë·ªì √°n (< 2000 xe), tr·∫£ v·ªÅ h·∫øt list l√† OK.
        for _, row in recsys.df_cars.iterrows():
            # S·ª≠ d·ª•ng l·∫°i h√†m map_car_to_frontend ƒë·ªÉ ƒë·∫£m b·∫£o c·∫•u tr√∫c JSON ƒë·ªìng nh·∫•t v·ªõi ph·∫ßn Chat
            # match_score = 0 v√¨ ƒë√¢y l√† danh s√°ch th√¥, kh√¥ng ph·∫£i g·ª£i √Ω c√° nh√¢n h√≥a
            car_obj = map_car_to_frontend(row, match_score=0)
            
            # Ghi ƒë√® matchReason m·∫∑c ƒë·ªãnh cho trang showroom
            car_obj['matchReason'] = "S·∫µn s√†ng giao ngay" 
            
            all_cars.append(car_obj)

        print(f"üì¶ [API] Showroom: ƒê√£ tr·∫£ v·ªÅ {len(all_cars)} xe.")
        return all_cars

    except Exception as e:
        print(f"‚ùå L·ªói l·∫•y danh s√°ch xe: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/retrain")
async def retrain_endpoint(background_tasks: BackgroundTasks):
    """
    API ƒë·ªÉ admin k√≠ch ho·∫°t h·ªçc l·∫°i t·ª´ feedback.
    Ch·∫°y ng·∫ßm (Background) ƒë·ªÉ kh√¥ng treo server.
    """
    background_tasks.add_task(recsys.retrain_model)
    return {"status": "success", "message": "ƒêang hu·∫•n luy·ªán l·∫°i model trong n·ªÅn..."}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)