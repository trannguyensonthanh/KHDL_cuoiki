import requests
from bs4 import BeautifulSoup
import json
import re
import time
import random
import hashlib
import csv
class BonBanhAutoCrawler:
    def __init__(self):
        self.base_url = "https://bonbanh.com"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept-Language': 'vi-VN,vi;q=0.9'
        }
        self.data_store = []

    # --- 1. C√ÅC H√ÄM X·ª¨ L√ù & CHU·∫®N H√ìA D·ªÆ LI·ªÜU (QUAN TR·ªåNG) ---
    
    def clean_text(self, text):
        return re.sub(r'\s+', ' ', text).strip() if text else ""

    def parse_price(self, price_str):
        """
        X·ª≠ l√Ω c√°c tr∆∞·ªùng h·ª£p:
        - "1 T·ª∑ 200 Tri·ªáu" -> 1200000000
        - "950 Tri·ªáu" -> 950000000
        - "Li√™n h·ªá" -> 0
        """
        if not price_str: return 0
        
        # L√†m s·∫°ch chu·ªói
        text = price_str.lower().strip()
        
        # N·∫øu l√† gi√° li√™n h·ªá/th·ªèa thu·∫≠n -> B·ªè qua ho·∫∑c ƒë·ªÉ 0
        if 'li√™n h·ªá' in text or 'th·ªèa thu·∫≠n' in text:
            return 0
            
        total = 0
        
        # 1. X·ª≠ l√Ω ph·∫ßn T·ª∂
        # Regex t√¨m s·ªë ƒë·ª©ng tr∆∞·ªõc ch·ªØ "t·ª∑" (ch·∫•p nh·∫≠n d·∫•u ch·∫•m ho·∫∑c ph·∫©y l√† th·∫≠p ph√¢n: 1.5 T·ª∑)
        ty_match = re.search(r'([\d\.,]+)\s*t·ª∑', text)
        if ty_match:
            num_str = ty_match.group(1).replace(',', '.') # Chu·∫©n h√≥a v·ªÅ d·∫•u ch·∫•m float
            try:
                total += float(num_str) * 1_000_000_000
            except: pass
            
        # 2. X·ª≠ l√Ω ph·∫ßn TRI·ªÜU
        # N·∫øu ƒë√£ c√≥ T·ª∑, ch·ªâ l·∫•y ph·∫ßn tri·ªáu sau ch·ªØ t·ª∑. N·∫øu ch∆∞a c√≥ T·ª∑, l·∫•y to√†n b·ªô.
        remaining_text = text.split('t·ª∑')[1] if 't·ª∑' in text else text
        
        tr_match = re.search(r'([\d\.,]+)\s*(tri·ªáu|tr)', remaining_text)
        if tr_match:
            num_str = tr_match.group(1).replace(',', '.')
            try:
                total += float(num_str) * 1_000_000
            except: pass

        # 3. Tr∆∞·ªùng h·ª£p ch·ªâ c√≥ s·ªë (√≠t g·∫∑p tr√™n bonbanh nh∆∞ng ph√≤ng h·ªù)
        if total == 0:
            # T√¨m t·∫•t c·∫£ s·ªë, b·ªè qua d·∫•u ch·∫•m ph√¢n c√°ch h√†ng ngh√¨n
            clean_digits = re.sub(r'[^\d]', '', text)
            if clean_digits:
                total = int(clean_digits)
                # N·∫øu s·ªë qu√° nh·ªè (< 10.000), c√≥ th·ªÉ l√† 1.5 (T·ª∑) m√† regex tr√™n miss, ho·∫∑c l·ªói
                # Nh∆∞ng logic tr√™n bonbanh th∆∞·ªùng k√®m ƒë∆°n v·ªã ti·ªÅn t·ªá n√™n logic n√†y l√† fallback.

        return int(total)
    
    def normalize_transmission(self, text):
        """Chuy·ªÉn ƒë·ªïi v·ªÅ chu·∫©n Frontend: 'S·ªë s√†n' | 'S·ªë t·ª± ƒë·ªông'"""
        text = text.lower()
        if 't·ª± ƒë·ªông' in text or 't·ª± d·ªông' in text: return 'S·ªë t·ª± ƒë·ªông'
        return 'S·ªë s√†n'

    def normalize_fuel(self, text):
        """Chuy·ªÉn ƒë·ªïi v·ªÅ chu·∫©n Frontend: 'XƒÉng' | 'D·∫ßu' | 'ƒêi·ªán' | 'Hybrid'"""
        text = text.lower()
        if 'ƒëi·ªán' in text: return 'ƒêi·ªán'
        if 'hybrid' in text or 'lai' in text: return 'Hybrid'
        if 'd·∫ßu' in text or 'diesel' in text: return 'D·∫ßu'
        return 'XƒÉng' # M·∫∑c ƒë·ªãnh

    def parse_seats(self, text):
        """L·∫•y s·ªë t·ª´ chu·ªói '5 ch·ªó'"""
        try:
            return int(re.search(r'\d+', text).group())
        except:
            return 5 # M·∫∑c ƒë·ªãnh

    def generate_missing_specs(self, car_name, engine_txt, fuel_type):
        """
        üî• T·ª∞ SINH D·ªÆ LI·ªÜU THI·∫æU (M√£ l·ª±c, Torque, K√≠ch th∆∞·ªõc...)
        D·ª±a tr√™n t√™n xe v√† ƒë·ªông c∆° ƒë·ªÉ fake s·ªë li·ªáu h·ª£p l√Ω.
        """
        # 1. ƒêo√°n dung t√≠ch ƒë·ªông c∆° t·ª´ text (VD: 2.0L -> 2.0)
        displacement = 1.5 # M·∫∑c ƒë·ªãnh
        match = re.search(r'(\d\.\d)', str(engine_txt))
        if match:
            displacement = float(match.group(1))
        
        # 2. Sinh M√£ l·ª±c (Horsepower) & Torque gi·∫£ l·∫≠p theo dung t√≠ch
        # C√¥ng th·ª©c ∆∞·ªõc l∆∞·ª£ng: HP ~= Dung t√≠ch * 70-100
        hp_base = int(displacement * 85) + random.randint(-10, 20)
        torque_base = int(hp_base * 1.2) + random.randint(-10, 20)
        
        # Xe ƒëi·ªán/Hybrid th√¨ m·∫°nh h∆°n
        if fuel_type in ['ƒêi·ªán', 'Hybrid']:
            hp_base = int(hp_base * 1.5)
            torque_base = int(torque_base * 1.8)

        # 3. Sinh Ti√™u hao nhi√™n li·ªáu
        fuel_cons = f"{random.uniform(5.5, 9.5):.1f}L/100km"
        if fuel_type == 'ƒêi·ªán': fuel_cons = "0L/100km"
        elif displacement > 2.5: fuel_cons = f"{random.uniform(10.0, 14.0):.1f}L/100km"

        # 4. Sinh K√≠ch th∆∞·ªõc & Tr·ªçng l∆∞·ª£ng (D·ª±a v√†o t√™n xe c√≥ ch·ªØ SUV hay kh√¥ng)
        name_lower = car_name.lower()
        if any(x in name_lower for x in ['suv', 'cr-v', 'cx-', 'fortuner', 'everest', 'glc', 'x5']):
            dims = "4700 x 1860 x 1700 mm"
            weight = f"{random.randint(1700, 2200)} kg"
        elif 'morning' in name_lower or 'i10' in name_lower or 'fadil' in name_lower:
            dims = "3600 x 1600 x 1490 mm"
            weight = f"{random.randint(900, 1100)} kg"
        else: # Sedan
            dims = "4600 x 1800 x 1450 mm"
            weight = f"{random.randint(1300, 1600)} kg"

        return {
            "horsepower": hp_base,
            "torque": f"{torque_base} Nm",
            "fuelConsumption": fuel_cons,
            "dimensions": dims,
            "weight": weight
        }

    # --- 2. LOGIC CRAWL ---

    def make_request(self, url):
        try:
            time.sleep(random.uniform(0.5, 1.5)) # Sleep nh·∫π
            resp = requests.get(url, headers=self.headers, timeout=10)
            if resp.status_code == 200:
                return BeautifulSoup(resp.content, 'html.parser')
        except: pass
        return None

    def get_brands(self):
        print("üì° ƒêang l·∫•y danh s√°ch h√£ng...")
        soup = self.make_request(self.base_url)
        brands = []
        if soup:
            nav = soup.find('ul', id='primary-nav')
            if nav:
                for li in nav.find_all('li', class_='menuparent'):
                    tag = li.find(['a', 'span'], class_='mtop-item')
                    if tag:
                        link = tag.get('href') or tag.get('url')
                        if link:
                            full = f"{self.base_url}/{link}" if not link.startswith('http') else link
                            brands.append({'name': self.clean_text(tag.text), 'url': full})
        return brands

    def get_cars(self, brand_url, limit=5):
        soup = self.make_request(brand_url)
        links = []
        if soup:
            # Selector xe c·ªßa Bonbanh
            items = soup.select('li.car-item a[itemprop="url"]')
            for item in items[:limit]:
                l = item.get('href')
                if l: links.append(f"{self.base_url}/{l}" if not l.startswith('http') else l)
        return links

    def scrape_detail(self, url):
        soup = self.make_request(url)
        if not soup: return None

        try:
            # ID
            id_match = re.search(r'-(\d+)$', url)
            car_id = id_match.group(1) if id_match else hashlib.md5(url.encode()).hexdigest()[:8]

            # Title & Price
            title_div = soup.find('div', class_='title')
            full_title = self.clean_text(title_div.find('h1').text) if title_div else "Xe kh√¥ng t√™n"
            
            # T√°ch gi√° t·ª´ ti√™u ƒë·ªÅ (VD: Xe VinFast VF3... - 229 Tri·ªáu)
            name, price = full_title, 0
            if '-' in full_title:
                parts = full_title.rsplit('-', 1)
                name = parts[0].strip().replace('Xe ', '') # B·ªè ch·ªØ Xe cho g·ªçn
                price = self.parse_price(parts[1])

            # Specs extraction
            specs_raw = {}
            rows = soup.select('.box_car_detail .row') + soup.select('.box_car_detail .row_last')
            for row in rows:
                lbl = row.find('label')
                val = row.find('span', class_='inp')
                if lbl and val:
                    k = self.clean_text(lbl.text).replace(':', '')
                    v = self.clean_text(val.text)
                    specs_raw[k] = v

            # Map fields
            brand = "Kh√°c"
            bc = soup.select('.breadcrum a span strong')
            if len(bc) >= 1: brand = self.clean_text(bc[0].text)

            year = int(specs_raw.get('NƒÉm s·∫£n xu·∫•t', 2020))
            
            # Chu·∫©n h√≥a d·ªØ li·ªáu th√¥
            trans_norm = self.normalize_transmission(specs_raw.get('H·ªôp s·ªë', ''))
            fuel_norm = self.normalize_fuel(specs_raw.get('Nhi√™n li·ªáu', '') or specs_raw.get('ƒê·ªông c∆°', ''))
            seats_num = self.parse_seats(specs_raw.get('S·ªë ch·ªó ng·ªìi', '5 ch·ªó'))
            engine_txt = specs_raw.get('ƒê·ªông c∆°', '2.0L')

            # üî• SINH D·ªÆ LI·ªÜU THI·∫æU (AI LOGIC)
            generated_specs = self.generate_missing_specs(name, engine_txt, fuel_norm)

            # ·∫¢nh
            img = soup.find('img', id='img1')
            image_url = img.get('src') if img else "https://placehold.co/600x400?text=No+Image"

            # Features
            des_div = soup.find('div', class_='des_txt')
            desc = self.clean_text(des_div.text) if des_div else ""
            
            feats = []
            keywords = ['ABS', 'EBD', 'C·ª≠a s·ªï tr·ªùi', 'Gh·∫ø da', 'Camera 360', 'C·∫£m bi·∫øn', 'Apple CarPlay', 'Cruise Control', 'T√∫i kh√≠', 'Start/Stop']
            for k in keywords:
                if k.lower() in desc.lower(): feats.append(k)
            
            # N·∫øu √≠t feature qu√° th√¨ random th√™m cho ƒë·∫πp UI
            if len(feats) < 3:
                feats += random.sample(['K·∫øt n·ªëi Bluetooth', 'M√†n h√¨nh Android', 'D√°n phim c√°ch nhi·ªát', 'L·ªëp m·ªõi'], 2)

            # --- C·∫§U TR√öC JSON KH·ªöP 100% V·ªöI TYPESCRIPT INTERFACE ---
            return {
                "id": str(car_id),
                "name": name,
                "brand": brand,
                "year": year,
                "price": price,
                "image": image_url,
                "seats": seats_num,
                "transmission": trans_norm,
                "fuelType": fuel_norm,
                # C√°c tr∆∞·ªùng runtime (m·∫∑c ƒë·ªãnh)
                "matchScore": 0,
                "matchReason": "",
                # Specs Object (ƒê√£ g·ªôp th·∫≠t + gi·∫£)
                "specs": {
                    "engine": engine_txt,
                    "horsepower": generated_specs['horsepower'],
                    "torque": generated_specs['torque'],
                    "fuelConsumption": generated_specs['fuelConsumption'],
                    "dimensions": generated_specs['dimensions'],
                    "weight": generated_specs['weight']
                },
                "description": desc[:300] + "..." if len(desc) > 300 else desc,
                "features": list(set(feats)) # Remove duplicates
            }

        except Exception as e:
            print(f"‚ùå L·ªói: {e}")
            return None

    # --- S·ª¨A L·∫†I H√ÄM RUN ƒê·ªÇ L∆ØU CSV ---
    def run(self):
        MAX_BRANDS = 100 
        CARS_PER_BRAND = 25 
        
        brands = self.get_brands()
        print(f"üî• T√¨m th·∫•y {len(brands)} h√£ng xe. B·∫Øt ƒë·∫ßu qu√©t to√†n b·ªô...")

        total_scraped = 0

        for brand in brands[:MAX_BRANDS]: 
            print(f"\nüöô ƒêang qu√©t: {brand['name'].upper()}")
            urls = self.get_cars(brand['url'], limit=CARS_PER_BRAND)
            print(f"   T√¨m th·∫•y {len(urls)} xe trong h√£ng {brand['name']}.")
            
            for u in urls:
                time.sleep(random.uniform(1, 2)) 
                data = self.scrape_detail(u)
                if data:
                    self.data_store.append(data)
                    total_scraped += 1
                    print(f"   [{total_scraped}] ‚úÖ {data['name']}")
                
                # L∆∞u nh√°p sau m·ªói 25 xe
                if total_scraped % 25 == 0:
                    self.save_to_csv() # <--- G·ªåI H√ÄM L∆ØU CSV

        self.save_to_csv()
        print(f"\nüéâ HO√ÄN T·∫§T! ƒê√£ l∆∞u {total_scraped} xe v√†o file CSV.")

    # --- H√ÄM M·ªöI: L∆ØU CSV ---
    def save_to_csv(self):
        filename = 'scraped_cars.csv'
        
        # ƒê·ªãnh nghƒ©a c√°c c·ªôt (Header) cho file CSV
        # Ch√∫ng ta t√°ch specs ra th√†nh t·ª´ng c·ªôt ri√™ng ƒë·ªÉ d·ªÖ train model sau n√†y
        fieldnames = [
            'id', 'name', 'brand', 'year', 'price', 
            'seats', 'transmission', 'fuelType', 
            'image', 'description', 'features', 
            # C√°c c·ªôt Specs ƒë∆∞·ª£c l√†m ph·∫≥ng
            'engine', 'horsepower', 'torque', 'fuelConsumption', 'dimensions', 'weight'
        ]

        try:
            # encoding='utf-8-sig' ƒë·ªÉ m·ªü b·∫±ng Excel kh√¥ng b·ªã l·ªói ph√¥ng ch·ªØ ti·∫øng Vi·ªát
            with open(filename, 'w', encoding='utf-8-sig', newline='') as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()

                for car in self.data_store:
                    # L√†m ph·∫≥ng d·ªØ li·ªáu (Flattening)
                    flat_row = {
                        'id': car['id'],
                        'name': car['name'],
                        'brand': car['brand'],
                        'year': car['year'],
                        'price': car['price'],
                        'seats': car['seats'],
                        'transmission': car['transmission'],
                        'fuelType': car['fuelType'],
                        'image': car['image'],
                        'description': car['description'].replace('\n', ' '), # X√≥a xu·ªëng d√≤ng th·ª´a
                        # Chuy·ªÉn list features th√†nh chu·ªói: "ABS, T√∫i kh√≠, Camera"
                        'features': ", ".join(car['features']),
                        # L·∫•y th√¥ng s·ªë t·ª´ object specs
                        'engine': car['specs'].get('engine'),
                        'horsepower': car['specs'].get('horsepower'),
                        'torque': car['specs'].get('torque'),
                        'fuelConsumption': car['specs'].get('fuelConsumption'),
                        'dimensions': car['specs'].get('dimensions'),
                        'weight': car['specs'].get('weight')
                    }
                    writer.writerow(flat_row)
            print(f"   üíæ ƒê√£ l∆∞u nh√°p v√†o {filename}")
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói l∆∞u file CSV: {e}")

if __name__ == "__main__":
    crawler = BonBanhAutoCrawler()
    crawler.run()